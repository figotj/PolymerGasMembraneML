{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "applied-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, Dense, Flatten, Activation\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "import kerastuner as kt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "harmful-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  # random search passes this hyperparameter() object\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv1D(hp.Int('input_units', min_value=32, max_value=256, step=32),\n",
    "                     kernel_size=hp.Int('kernel_size', min_value=8, max_value=32, step=8),\n",
    "                     activation='relu',kernel_regularizer=\"l2\", input_shape=x_train.shape[1:]))\n",
    "\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "   \n",
    "\n",
    "    for i in range(hp.Int('n_layers', 0, 2)):  # adding variation of layers.\n",
    "        model.add(Conv1D(hp.Int('input_units', min_value=32, max_value=256, step=32), \n",
    "                         kernel_size=8, activation='relu',kernel_regularizer=\"l2\"))\n",
    "\n",
    "        #model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.Int('fully_units',\n",
    "                                min_value=20,\n",
    "                                max_value=100,\n",
    "                                step=20), activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=0.005),\n",
    "                  loss=\"mean_absolute_error\",\n",
    "                  metrics=[\"mean_absolute_error\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-circuit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    " \n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    #objective='mean_absolute_error',\n",
    "    objective=kt.Objective('val_mean_absolute_error', 'min'),\n",
    "    max_trials=100,  # how many model variations to test?\n",
    "    executions_per_trial=1,  # how many trials per variation? (same model could perform differently)\n",
    "    directory=LOG_DIR)\n",
    "\n",
    "\n",
    "tuner.search(x=x_train,\n",
    "             y=y_train,\n",
    "             verbose=2, # just slapping this here bc jupyter notebook. The console out was getting messy.\n",
    "             epochs=40,\n",
    "             batch_size=16,\n",
    "             #callbacks=[tensorboard],  # if you have callbacks like tensorboard, they go here.\n",
    "             validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
